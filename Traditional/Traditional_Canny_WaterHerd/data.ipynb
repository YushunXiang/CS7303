{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "revise path for your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/data/DATA/ADE20K\"\n",
    "data_path = \"/data/DATA/ADE20K/ADEChallengeData2016\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load related packages and visualize catalogue of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "annotations_path = os.path.join(data_path, \"annotations\")\n",
    "annotations_instance_path = os.path.join(annotations_path, \"annotations_instance\")\n",
    "sceneCategories_path = os.path.join(annotations_path, \"sceneCategories.txt\")\n",
    "images_path = os.path.join(data_path, \"images\")\n",
    "objectInfo150_path = os.path.join(data_path, \"objectInfo150.txt\")\n",
    "annotations_detectron2_path = os.path.join(annotations_path, \"annotations_detectron2\")\n",
    "\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initilize config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \n",
    "    class DATASET:\n",
    "        root_dataset= data_root\n",
    "        list_val= \"Data/validation.odgt\"\n",
    "        num_class= 150\n",
    "        imgSizes= (300, 375, 450, 525, 600)\n",
    "        imgMaxSize= 1000\n",
    "        padding_constant= 32\n",
    "        segm_downsampling_rate= 4\n",
    "        random_flip: True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load dataset and initialize dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataset import ValDataset\n",
    "from PIL import Image\n",
    "\n",
    "cfg = Config()\n",
    "# Dataset and Loader\n",
    "dataset_val = ValDataset(\n",
    "    cfg.DATASET.root_dataset,\n",
    "    cfg.DATASET.list_val,\n",
    "    cfg.DATASET)\n",
    "loader_val = torch.utils.data.DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define appropriate metrics for image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, label):\n",
    "    valid = (label >= 0)\n",
    "    acc_sum = (valid * (preds == label)).sum()\n",
    "    valid_sum = valid.sum()\n",
    "    acc = float(acc_sum) / (valid_sum + 1e-10)\n",
    "    return acc, valid_sum\n",
    "\n",
    "def intersectionAndUnion(imPred, imLab, numClass):\n",
    "    imPred = np.asarray(imPred).copy()\n",
    "    imLab = np.asarray(imLab).copy()\n",
    "\n",
    "    imPred += 1\n",
    "    imLab += 1\n",
    "    # Remove classes from unlabeled pixels in gt image.\n",
    "    # We should not penalize detections in unlabeled portions of the image.\n",
    "    imPred = imPred * (imLab > 0)\n",
    "\n",
    "    # Compute area intersection:\n",
    "    intersection = imPred * (imPred == imLab)\n",
    "    (area_intersection, _) = np.histogram(\n",
    "        intersection, bins=numClass, range=(1, numClass))\n",
    "\n",
    "    # Compute area union:\n",
    "    (area_pred, _) = np.histogram(imPred, bins=numClass, range=(1, numClass))\n",
    "    (area_lab, _) = np.histogram(imLab, bins=numClass, range=(1, numClass))\n",
    "    area_union = area_pred + area_lab - area_intersection\n",
    "\n",
    "    return (area_intersection, area_union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with different traditional segmentation methods and visualization selected samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import collections\n",
    "from sklearn.cluster import KMeans\n",
    "from torch.autograd import Variable\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "        self.val = None\n",
    "        self.avg = None\n",
    "        self.sum = None\n",
    "        self.count = None\n",
    "\n",
    "    def initialize(self, val, weight):\n",
    "        self.val = val\n",
    "        self.avg = val\n",
    "        self.sum = val * weight\n",
    "        self.count = weight\n",
    "        self.initialized = True\n",
    "\n",
    "    def update(self, val, weight=1):\n",
    "        if not self.initialized:\n",
    "            self.initialize(val, weight)\n",
    "        else:\n",
    "            self.add(val, weight)\n",
    "\n",
    "    def add(self, val, weight):\n",
    "        self.val = val\n",
    "        self.sum += val * weight\n",
    "        self.count += weight\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def value(self):\n",
    "        return self.val\n",
    "\n",
    "    def average(self):\n",
    "        return self.avg\n",
    "\n",
    "def as_numpy(obj):\n",
    "    if isinstance(obj, collections.Sequence):\n",
    "        return [as_numpy(v) for v in obj]\n",
    "    elif isinstance(obj, collections.Mapping):\n",
    "        return {k: as_numpy(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, Variable):\n",
    "        return obj.data.cpu().numpy()\n",
    "    elif torch.is_tensor(obj):\n",
    "        return obj.cpu().numpy()\n",
    "    else:\n",
    "        \n",
    "        return np.array(obj)\n",
    "\n",
    "def traditional_watershed_segmentation(image, num_classes):\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    \n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
    "  \n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "    _, sure_fg = cv2.threshold(dist_transform, 0.5*dist_transform.max(), 255, 0)\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    _, markers = cv2.connectedComponents(sure_fg)\n",
    "    markers = markers + 1\n",
    "    markers[unknown == 255] = 0\n",
    "    \n",
    "    markers = cv2.watershed(image, markers)\n",
    "    \n",
    "    unique_markers = np.unique(markers)\n",
    "    if len(unique_markers) > num_classes:\n",
    "\n",
    "        lab_image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "        region_features = []\n",
    "        for marker in unique_markers:\n",
    "            if marker == -1:  \n",
    "                continue\n",
    "            mask = (markers == marker)\n",
    "            region_mean = np.mean(lab_image[mask], axis=0)\n",
    "            region_features.append(region_mean)\n",
    "            \n",
    "        kmeans = MiniBatchKMeans(n_clusters=num_classes, random_state=42)\n",
    "        region_labels = kmeans.fit_predict(region_features)\n",
    "        \n",
    "\n",
    "        new_markers = np.zeros_like(markers)\n",
    "        for i, marker in enumerate(unique_markers):\n",
    "            if marker == -1:\n",
    "                continue\n",
    "            new_markers[markers == marker] = region_labels[i-1] \n",
    "        markers = new_markers\n",
    "    \n",
    "    return markers.astype(np.int32)\n",
    "\n",
    "def traditional_canny_edge_segmentation(image, num_classes):\n",
    "\n",
    "    scale_factor = 0.5\n",
    "    h, w = image.shape[:2]\n",
    "    small_h, small_w = int(h * scale_factor), int(w * scale_factor)\n",
    "    small_image = cv2.resize(image, (small_w, small_h))\n",
    "\n",
    "    lab_image = cv2.cvtColor(small_image, cv2.COLOR_RGB2LAB)\n",
    "    \n",
    "\n",
    "    y, x = np.mgrid[0:small_h, 0:small_w]\n",
    "    x = x / small_w * 255\n",
    "    y = y / small_h * 255\n",
    "\n",
    "    features = np.concatenate([\n",
    "        lab_image.reshape(-1, 3),\n",
    "        x.reshape(-1, 1) * 0.2,\n",
    "        y.reshape(-1, 1) * 0.2\n",
    "    ], axis=1)\n",
    "    \n",
    "    kmeans = MiniBatchKMeans(\n",
    "        n_clusters=num_classes,\n",
    "        batch_size=1000,  \n",
    "        random_state=42,\n",
    "        n_init='auto'\n",
    "    )\n",
    "    labels = kmeans.fit_predict(features)\n",
    "\n",
    "    segmentation = labels.reshape(small_h, small_w)\n",
    "\n",
    "    segmentation = cv2.resize(\n",
    "        segmentation.astype(float), \n",
    "        (w, h), \n",
    "        interpolation=cv2.INTER_NEAREST\n",
    "    )\n",
    "    \n",
    "    return segmentation.astype(np.int32)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "def visualize_image(img_tensor):\n",
    "    if torch.is_tensor(img_tensor):\n",
    "        img_array = img_tensor.cpu().numpy()\n",
    "    else:\n",
    "        img_array = img_tensor  \n",
    "        \n",
    "    if img_array.ndim == 3 and img_array.shape[0] in [1, 3]:\n",
    "        img_array = np.transpose(img_array, (1, 2, 0))\n",
    "    \n",
    "    if img_array.min() < 0 or img_array.max() > 1:\n",
    "        img_array = (img_array - img_array.min()) / (img_array.max() - img_array.min())\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.imshow(img_array)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_segmentation(segmentation_map):\n",
    "    \"\"\"\n",
    "    可视化分割结果\n",
    "    Args:\n",
    "        segmentation_map: shape应该是(H, W)的2D数组\n",
    "    \"\"\"\n",
    "    # 确保输入是2D数组\n",
    "    if segmentation_map.ndim > 2:\n",
    "        segmentation_map = segmentation_map.squeeze()\n",
    "    \n",
    "    # 生成随机颜色映射\n",
    "    np.random.seed(42)  # 保持颜色一致性\n",
    "    colors = np.random.randint(0, 255, (150, 3), dtype=np.uint8)\n",
    "    colors[0] = [0, 0, 0]  # 背景设为黑色\n",
    "    \n",
    "    # 创建彩色可视化图\n",
    "    visualization = colors[segmentation_map.astype(np.int32)]\n",
    "    \n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.imshow(visualization.astype(np.uint8))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "acc_meter = AverageMeter()\n",
    "intersection_meter = AverageMeter()\n",
    "union_meter = AverageMeter()\n",
    "time_meter = AverageMeter()\n",
    "\n",
    "for i, one_batch in enumerate(loader_val):\n",
    "    original_image = one_batch['img_ori'][0]\n",
    "    resized_images = one_batch['img_data']\n",
    "    seg_label = one_batch['seg_label'][0]\n",
    "    \n",
    "    if i == 0:\n",
    "        visualize_image(seg_label)\n",
    "        visualize_image(original_image)\n",
    "\n",
    "        \n",
    "    pred = traditional_canny_edge_segmentation(as_numpy(original_image), cfg.DATASET.num_class)\n",
    "    visualize_image(as_numpy(pred)[None, ...])\n",
    "        \n",
    "    acc, pix = accuracy(as_numpy(pred), as_numpy(seg_label))\n",
    "\n",
    "    intersection, union = intersectionAndUnion(as_numpy(pred), as_numpy(seg_label), cfg.DATASET.num_class)\n",
    "    acc_meter.update(acc, pix)\n",
    "    intersection_meter.update(intersection)\n",
    "    union_meter.update(union)\n",
    "\n",
    "iou = intersection_meter.sum / (union_meter.sum + 1e-10)\n",
    "for i, _iou in enumerate(iou):\n",
    "    print('class [{}], IoU: {:.4f}'.format(i, _iou))\n",
    "\n",
    "print('[Eval Summary]:')\n",
    "print('Mean IoU: {:.4f}, Accuracy: {:.2f}%'.format(iou.mean(), acc_meter.average()*100))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
